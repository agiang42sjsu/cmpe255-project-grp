{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: surprise in c:\\users\\tiffany\\anaconda3\\lib\\site-packages (0.1)\n",
      "Requirement already satisfied: scikit-surprise in c:\\users\\tiffany\\anaconda3\\lib\\site-packages (from surprise) (1.1.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\tiffany\\anaconda3\\lib\\site-packages (from scikit-surprise->surprise) (1.0.1)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\tiffany\\anaconda3\\lib\\site-packages (from scikit-surprise->surprise) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.11.2 in c:\\users\\tiffany\\anaconda3\\lib\\site-packages (from scikit-surprise->surprise) (1.19.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\tiffany\\anaconda3\\lib\\site-packages (from scikit-surprise->surprise) (1.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from surprise import AlgoBase\n",
    "from surprise import NormalPredictor\n",
    "from surprise import PredictionImpossible\n",
    "from surprise import KNNBasic\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading MA_users.json\n",
      "Time taken to load user data: 1 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "with open('MA_users.json', encoding=\"utf8\") as fin:\n",
    "    print('Reading',fin.name)\n",
    "    user_data = json.load(fin)\n",
    "end = time.time()\n",
    "duration_without_dr = end-start\n",
    "print(\"Time taken to load user data: %d seconds\" %duration_without_dr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading MA_restaurants.json\n",
      "Time taken to load restaurant data: 0 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "with open('MA_restaurants.json', encoding=\"utf8\") as fin:\n",
    "    print('Reading',fin.name)\n",
    "    restaurant_data = json.load(fin)\n",
    "end = time.time()\n",
    "duration_without_dr = end-start\n",
    "print(\"Time taken to load restaurant data: %d seconds\" %duration_without_dr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading MA_reviews.json\n",
      "Time taken to load review data: 5 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "with open('MA_reviews.json', encoding=\"utf8\") as fin:\n",
    "    print('Reading',fin.name)\n",
    "    review_data = json.load(fin)\n",
    "end = time.time()\n",
    "duration_without_dr = end-start\n",
    "print(\"Time taken to load review data: %d seconds\" %duration_without_dr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125521 user records loaded\n",
      "914710 review records loaded\n",
      "10550 business records loaded\n"
     ]
    }
   ],
   "source": [
    "print(str(len(user_data)) + ' user records loaded')\n",
    "print(str(len(review_data)) + ' review records loaded')\n",
    "print(str(len(restaurant_data)) + ' business records loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['user_id', 'name', 'review_count', 'yelping_since', 'useful', 'funny', 'cool', 'elite', 'friends', 'fans', 'average_stars', 'compliment_hot', 'compliment_more', 'compliment_profile', 'compliment_cute', 'compliment_list', 'compliment_note', 'compliment_plain', 'compliment_cool', 'compliment_funny', 'compliment_writer', 'compliment_photos']) \n",
      "\n",
      "dict_keys(['review_id', 'user_id', 'business_id', 'stars', 'useful', 'funny', 'cool', 'text', 'date']) \n",
      "\n",
      "dict_keys(['business_id', 'name', 'address', 'city', 'state', 'postal_code', 'latitude', 'longitude', 'stars', 'review_count', 'is_open', 'attributes', 'categories', 'hours']) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(user_data[0].keys(),'\\n')\n",
    "print(review_data[0].keys(),'\\n')\n",
    "print(restaurant_data[0].keys(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: nl8gWLDo6U6MjqzbBmE_9A\n",
      "name: Vivian\n",
      "review_count: 1871\n",
      "yelping_since: 2008-08-04 15:36:54\n",
      "useful: 3624\n",
      "funny: 1018\n",
      "cool: 1477\n",
      "elite: 2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,20,20\n",
      "friends: [list of user ids]\n",
      "fans: 195\n",
      "average_stars: 3.57\n",
      "compliment_hot: 55\n",
      "compliment_more: 12\n",
      "compliment_profile: 1\n",
      "compliment_cute: 2\n",
      "compliment_list: 10\n",
      "compliment_note: 47\n",
      "compliment_plain: 210\n",
      "compliment_cool: 113\n",
      "compliment_funny: 113\n",
      "compliment_writer: 59\n",
      "compliment_photos: 62\n"
     ]
    }
   ],
   "source": [
    "user_id_dict = dict()\n",
    "for i,u in enumerate(user_data):\n",
    "    user_id_dict[u['user_id']] = i\n",
    "\n",
    "def print_user_info(user_id):\n",
    "    for attr in user_data[user_id_dict[user_id]].keys():\n",
    "        print('{0}: {1}'.format(str(attr), str(user_data[user_id_dict[user_id]][attr]) if attr != 'friends' else '[list of user ids]'))\n",
    "        \n",
    "print_user_info('nl8gWLDo6U6MjqzbBmE_9A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review_id: lWC-xP3rd6obsecCYsGZRg\n",
      "user_id: ak0TdVmGKo4pwqdJSTLwWw\n",
      "business_id: buF9druCkbuXLX526sGELQ\n",
      "stars: 4.0\n",
      "useful: 3\n",
      "funny: 1\n",
      "cool: 1\n",
      "text: Apparently Prides Osteria had a rough summer as evidenced by the almost empty dining room at 6:30 on a Friday night. However new blood in the kitchen seems to have revitalized the food from other customers recent visits. Waitstaff was warm but unobtrusive. By 8 pm or so when we left the bar was full and the dining room was much more lively than it had been. Perhaps Beverly residents prefer a later seating. \n",
      "\n",
      "After reading the mixed reviews of late I was a little tentative over our choice but luckily there was nothing to worry about in the food department. We started with the fried dough, burrata and prosciutto which were all lovely. Then although they don't offer half portions of pasta we each ordered the entree size and split them. We chose the tagliatelle bolognese and a four cheese filled pasta in a creamy sauce with bacon, asparagus and grana frita. Both were very good. We split a secondi which was the special Berkshire pork secreto, which was described as a pork skirt steak with garlic potato purÃ©e and romanesco broccoli (incorrectly described as a romanesco sauce). Some tables received bread before the meal but for some reason we did not. \n",
      "\n",
      "Management also seems capable for when the tenants in the apartment above began playing basketball she intervened and also comped the tables a dessert. We ordered the apple dumpling with gelato and it was also quite tasty. Portions are not huge which I particularly like because I prefer to order courses. If you are someone who orders just a meal you may leave hungry depending on you appetite. Dining room was mostly younger crowd while the bar was definitely the over 40 set. Would recommend that the naysayers return to see the improvement although I personally don't know the former glory to be able to compare. Easy access to downtown Salem without the crowds on this month of October.\n",
      "date: 2014-10-11 03:34:02\n"
     ]
    }
   ],
   "source": [
    "for attr in review_data[0].keys():\n",
    "    print('{0}: {1}'.format(str(attr), str(review_data[0][attr])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business_id: zMpWhHh6Cp1BkFRM8cbPhA\n",
      "name: Tasting Counter\n",
      "address: 14 Tyler St\n",
      "city: Somerville\n",
      "state: MA\n",
      "postal_code: 02143\n",
      "latitude: 42.3817829\n",
      "longitude: -71.1056689\n",
      "stars: 4.5\n",
      "review_count: 190\n",
      "is_open: 1\n",
      "attributes: {'RestaurantsPriceRange2': '4', 'RestaurantsTakeOut': 'False', 'RestaurantsDelivery': 'False', 'BusinessAcceptsCreditCards': 'True', 'OutdoorSeating': 'False', 'RestaurantsReservations': 'True', 'Alcohol': \"u'beer_and_wine'\", 'WiFi': \"u'no'\", 'BusinessAcceptsBitcoin': 'False', 'NoiseLevel': \"u'average'\", 'HasTV': 'False', 'RestaurantsAttire': \"u'dressy'\", 'Caters': 'False', 'BusinessParking': \"{'garage': False, 'street': True, 'validated': False, 'lot': True, 'valet': False}\", 'DogsAllowed': 'False', 'RestaurantsTableService': 'True', 'WheelchairAccessible': 'True', 'ByAppointmentOnly': 'True', 'RestaurantsGoodForGroups': 'False', 'GoodForKids': 'False', 'BikeParking': 'True', 'GoodForMeal': \"{'dessert': False, 'latenight': False, 'lunch': False, 'dinner': True, 'brunch': False, 'breakfast': False}\", 'BYOB': 'False', 'Ambience': \"{'touristy': False, 'hipster': False, 'romantic': False, 'divey': False, 'intimate': False, 'trendy': False, 'upscale': False, 'classy': True, 'casual': False}\"}\n",
      "categories: American (New), Event Planning & Services, Restaurants, Food, Caterers, Personal Chefs\n",
      "hours: {'Thursday': '17:0-21:30', 'Friday': '17:0-21:30', 'Saturday': '17:0-21:30', 'Sunday': '17:0-21:30'}\n"
     ]
    }
   ],
   "source": [
    "business_id_dict = dict()\n",
    "for i,r in enumerate(restaurant_data):\n",
    "    business_id_dict[r['business_id']] = i\n",
    "\n",
    "def print_business_info(business_id):\n",
    "    for attr in restaurant_data[business_id_dict[business_id]].keys():\n",
    "        print('{0}: {1}'.format(str(attr), str(restaurant_data[business_id_dict[business_id]][attr])))\n",
    "        \n",
    "print_business_info('zMpWhHh6Cp1BkFRM8cbPhA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a 2d arary of user IDs and buisness IDs, with ratings(stars) as frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125521, 10550)\n",
      "number of non-zero elements(good ratings): 879189\n"
     ]
    }
   ],
   "source": [
    "rating_mat = np.zeros((len(user_data), len(restaurant_data)))\n",
    "rating_dict = {'user_id': [],\n",
    "               'business_id': [],\n",
    "               'rating': []}\n",
    "\n",
    "for review in review_data:\n",
    "    user_idx = user_id_dict[review['user_id']]\n",
    "    business_idx = business_id_dict[review['business_id']]\n",
    "    rating_mat[user_idx][business_idx] = review['stars']\n",
    "    \n",
    "    rating_dict['user_id'].append(review['user_id'])\n",
    "    rating_dict['business_id'].append(review['business_id'])\n",
    "    rating_dict['rating'].append(review['stars'])\n",
    "\n",
    "print(rating_mat.shape)\n",
    "print('number of non-zero elements(good ratings): ' +str(np.count_nonzero(rating_mat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original data frame shape:\t(914710, 3)\n",
      "The new data frame shape:\t(215691, 3)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(rating_dict)\n",
    "\n",
    "# filter to only the users/businesses with over 50 reviews\n",
    "# necessary in order to build the anti testset\n",
    "filter_user = df['user_id'].value_counts() > 50\n",
    "filter_user = filter_user[filter_user].index.tolist()\n",
    "\n",
    "filter_business = df['business_id'].value_counts() > 50\n",
    "filter_business = filter_business[filter_business].index.tolist()\n",
    "\n",
    "df_new = df[(df['user_id'].isin(filter_user)) & (df['business_id'].isin(filter_business))]\n",
    "\n",
    "print('The original data frame shape:\\t{}'.format(df.shape))\n",
    "print('The new data frame shape:\\t{}'.format(df_new.shape))\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df_new[['user_id', 'business_id', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up some memory\n",
    "del rating_mat\n",
    "del df\n",
    "\n",
    "sim_options = {'name': 'cosine',\n",
    "               'user_based': False}\n",
    "trainset = data.build_full_trainset()\n",
    "algo = KNNWithMeans(sim_options=sim_options)\n",
    "algo.fit(trainset)\n",
    "\n",
    "# note: this takes quite a while...\n",
    "testset = trainset.build_anti_testset()\n",
    "predictions = algo.test(testset)\n",
    "dump.dump('./predictions', predictions, algo=KNNWithMeans())\n",
    "# predictions = dump.load('./predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 'nl8gWLDo6U6MjqzbBmE_9A'\n",
    "business_id = 'CoZmZKv2lCYd'\n",
    "print(algo.predict(uid=user_id, iid=business_id))\n",
    "print(predictions[1])\n",
    "\n",
    "topn = defaultdict(list)\n",
    "n = 5\n",
    "\n",
    "for uid, bid, _, est, _ in predictions:\n",
    "    topn[uid].append((bid, est))\n",
    "\n",
    "for uid, est in topn.items():\n",
    "    est.sort(key=lambda x: x[1], reverse=True)\n",
    "    topn[uid] = est[:n]\n",
    "\n",
    "user_results = pd.DataFrame.from_dict(topn).transpose().loc[user_id]\n",
    "print('Top {0} recommendations for user {1}\\n{2}'.format(n, user_id, user_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm and Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation methods\n",
    "Parameter grid search given the below error measurements:\n",
    "#### Root Mean Square Error (RMSE)\n",
    "* Measures standard deviation of errors in set of predictions\n",
    "* Goal: minimize RMSE\n",
    "\n",
    "#### Mean Absolute Error (MAE)\n",
    "* Measures average magnitude of errors in set of predictions\n",
    "* Goal: minimize MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rating_dict)\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df[['user_id', 'business_id', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get and shuffle ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ratings= data.raw_ratings\n",
    "random.shuffle(raw_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Data (Train 80%-Test 20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_boundary = int(.8 * len(raw_ratings))\n",
    "trainset_ratings = raw_ratings[:split_boundary]\n",
    "testset_ratings = raw_ratings[split_boundary:]\n",
    "\n",
    "#set data to training_set\n",
    "data.raw_ratings = trainset_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select best params/algo with Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_options = {\n",
    "    \"name\": [\"msd\", \"cosine\"],\n",
    "    \"min_support\": [3, 4, 5],\n",
    "    \"user_based\": [False]\n",
    "}\n",
    "param_grid = {\"sim_options\": sim_options}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "trainset = data.build_full_trainset()\n",
    "grid_search = GridSearchCV(KNNBasic, param_grid, measures = [\"rmse\", \"mae\"], cv=3)\n",
    "grid_search.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2882728325118868\n",
      "{'sim_options': {'name': 'msd', 'min_support': 5, 'user_based': False}}\n",
      "1.003291739981118\n",
      "{'sim_options': {'name': 'msd', 'min_support': 3, 'user_based': False}}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_score[\"rmse\"])\n",
    "print(grid_search.best_params[\"rmse\"])\n",
    "\n",
    "print(grid_search.best_score[\"mae\"])\n",
    "print(grid_search.best_params[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = grid_search.best_estimator['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x25b8fa0e2e0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retrain on the whole training set\n",
    "trainset = data.build_full_trainset()\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute biased accuracy of training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biased accuracy on training set: \n",
      "RMSE: 0.6127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.612657228372552"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = algo.test(trainset.build_testset())\n",
    "print(\"Biased accuracy on training set: \")\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute unbiased accuracy of the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbiased accuracy on training set: \n",
      "RMSE: 1.2677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.2677097435104183"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset = data.construct_testset(testset_ratings)\n",
    "predictions = algo.test(testset)\n",
    "print(\"Unbiased accuracy on training set: \")\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat process with KNNWithMeans Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rating_dict)\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df[['user_id', 'business_id', 'rating']], reader)\n",
    "\n",
    "# set data to training set\n",
    "data.raw_ratings = trainset_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "from surprise import KNNWithMeans\n",
    "\n",
    "grid_search = GridSearchCV(KNNWithMeans, param_grid, measures = [\"rmse\", \"mae\"], cv=3)\n",
    "grid_search.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2109716403698287\n",
      "{'sim_options': {'name': 'cosine', 'min_support': 5, 'user_based': False}}\n",
      "0.9425676047709648\n",
      "{'sim_options': {'name': 'cosine', 'min_support': 3, 'user_based': False}}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_score[\"rmse\"])\n",
    "print(grid_search.best_params[\"rmse\"])\n",
    "\n",
    "print(grid_search.best_score[\"mae\"])\n",
    "print(grid_search.best_params[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = grid_search.best_estimator['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNWithMeans at 0x25b8fa01670>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrain on the whole training set\n",
    "trainset = data.build_full_trainset()\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute biased accuracy of training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biased accuracy on training set: \n",
      "RMSE: 0.7779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7778719684014103"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = algo.test(trainset.build_testset())\n",
    "print(\"Biased accuracy on training set: \")\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute unbiased accuracy of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbiased accuracy on training set: \n",
      "RMSE: 1.1891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.189111605607265"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset = data.construct_testset(testset_ratings)\n",
    "predictions = algo.test(testset)\n",
    "print(\"Unbiased accuracy on training set: \")\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter and Algorithm Tuning Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best (smallest) MAE and RMSE score for collaborative filtering on the yelp dataset use the following params:\n",
    "\n",
    "* KNNWithMeans\n",
    "* cosine similarity\n",
    "* minimum support of 5? \n",
    "* not user_based\n",
    "\n",
    "(Note to team members -I notice someone was able to run the true, if so perhaps we should integrate into the grid search above and tell me if its more efficient than false? the only thing is I wont be able to run it, so if false has a better score than perhaps we should hold off but definitely use it in our final implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 86.4 GiB for an array with shape (107666, 107666) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-d551037e136a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKNNBasic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeasures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"rmse\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"mae\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\surprise\\model_selection\\search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     86\u001b[0m                                                        cv.split(data))\n\u001b[0;32m     87\u001b[0m         )\n\u001b[1;32m---> 88\u001b[1;33m         out = Parallel(n_jobs=self.n_jobs,\n\u001b[0m\u001b[0;32m     89\u001b[0m                        \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m                        verbose=self.joblib_verbose)(delayed_list)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1039\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1041\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\surprise\\model_selection\\validation.py\u001b[0m in \u001b[0;36mfit_and_score\u001b[1;34m(algo, trainset, testset, measures, return_train_measures)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[0mstart_fit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m     \u001b[0malgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m     \u001b[0mfit_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[0mstart_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\surprise\\prediction_algorithms\\knns.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, trainset)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mSymmetricAlgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_similarities\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\surprise\\prediction_algorithms\\algo_base.py\u001b[0m in \u001b[0;36mcompute_similarities\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'verbose'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Computing the {0} similarity matrix...'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m             \u001b[0msim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstruction_func\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'verbose'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Done computing similarity matrix.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\surprise\\similarities.pyx\u001b[0m in \u001b[0;36msurprise.similarities.msd\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 86.4 GiB for an array with shape (107666, 107666) and data type float64"
     ]
    }
   ],
   "source": [
    "sim_options = {\n",
    "    \"name\": [\"msd\", \"cosine\"],\n",
    "    \"min_support\": [3, 4, 5],\n",
    "    \"user_based\": [True]\n",
    "}\n",
    "param_grid = {\"sim_options\": sim_options}\n",
    "\n",
    "grid_search = GridSearchCV(KNNBasic, param_grid, measures = [\"rmse\", \"mae\"], cv=3)\n",
    "grid_search.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
